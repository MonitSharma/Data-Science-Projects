{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Frame_Level_Speech_Recoginiton4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "g9n37Pf8isj2"
      },
      "source": [
        "# Frame Level Speech Recognition with Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "LQapFrR021Dm"
      },
      "source": [
        "## Question for the Assesment\n",
        "In this coursework you will take your knowledge of feedforward neural networks and apply it to the task of speech recognition.\n",
        "\n",
        "You are provided a dataset of audio recordings (utterances) and their phoneme state (subphoneme) labels. The data comes from articles published in the Wall Street Journal (WSJ) that are read aloud and labelled using the original text. If you have not encountered speech data before or have not heard of phonemes or spectrograms, we will clarify these here:\n",
        "\n",
        "Phonems and Phoneme States\n",
        "As letters are the atomic elements of written language, phonemes are the atomic elements of speech. It is crucial for us to have a means to distiguish different sounds in speech that may or may not represent the same letter or combinations of letters in the written alphabet. For example, the words \"jet\" and \"ridge\" both contain the same sound and we refer to this elemental sound as the phoneme \"JH\". For this challenge we will consider 46 phonemes in the english language.\n",
        "\n",
        "[\"+BREATH+\", \"+COUGH+\", \"+NOISE+\", \"+SMACK+\", \"+UH+\", \"+UM+\", \"AA\", \"AE\", \"AH\", \"AO\", \"AW\", \"AY\", \"B\", \"CH\", \"D\", \"DH\", \"EH\", \"ER\", \"EY\", \"F\", \"G\", \"HH\", \"IH\", \"IY\", \"JH\", \"K\", \"L\", \"M\", \"N\", \"NG\", \"OW\", \"OY\", \"P\", \"R\", \"S\", \"SH\", \"SIL\", \"T\", \"TH\", \"UH\", \"UW\", \"V\", \"W\", \"Y\", \"Z\", \"ZH\"]\n",
        "\n",
        "A powerful technique in speech recognition is to model speech as a markov process with unobserved states. This model considers observed speech to be dependent on unobserved state transitions. We refer to these unobserved states as phoneme states or subphonemes. For each phoneme, there are 3 respective phoneme states. Therefore for our 46 phonemes, there exist 138 respective phoneme states.\n",
        "\n",
        "Hidden Markov Models (HMMs) estimate the parameters of this unobserved markov process (transition and emission probabilities) that maximize the likelihood of the observed speech data.\n",
        "\n",
        "Your task is to instead take a model-free approach and classify mel spectrogram frames using a neural network that takes a frame (plus optional context) and outputs class probabilities for all 138 phoneme states. Performance on the task will be measured by classification accuracy on a held-out set of labelled mel spectrogram frames. Training/dev labels are provided as integers [0-137].\n",
        "\n",
        "Representing Speech\n",
        "As a first step, the speech must be converted into a feature representation that can be fed into the network.\n",
        "\n",
        "In our representation, utterances have been converted to \"mel spectrograms\", which are pictorial representations that characterize how the frequency content of the signal varies with time. The frequency-domain of the audio signal provides more useful features for distinguishing phonemes.\n",
        "\n",
        "For a more intuitive understanding, consider attempting to determine which instruments are playing in an orchestra given an audio recording of a performance. By looking only at the amplitude of the signal of the orchestra over time, it is nearly impossible to distinguish one source from another. But if the signal is transformed into the frequency domain, we can use our knowledge that flutes produce higher frequency sounds and bassoons produce lower frequency sounds. In speech, a similar phenomenon is observed when the vocal tract produces sounds at varying frequencies.\n",
        "\n",
        "To convert the speech to a mel spectrogram, it is segmented into little \"frames\", each 25ms wide, where the \"stride\" between adjacent frames is 10ms. Thus we get 100 such frames per second of speech.\n",
        "\n",
        "From each frame, we compute a single \"mel spectral\" vector, where the components of the vector represent the (log) energy in the signal in different frequency bands. In the data we have given you, we have 40-dimensional mel-spectral vectors, i.e. we have computed energies in 40 frequency bands.\n",
        "\n",
        "Thus, we get 100 40-dimensional mel spectral (row) vectors per second of speech in the recording. Each one of these vectors is referred to as a frame. The details of how mel spectrograms are computed from speech is explained in the attached blog.\n",
        "\n",
        "Thus, for a T-second recording, the entire spectrogram is a 100T x 40 matrix, comprising 100T 40- dimensional vectors (at 100 vectors (frames) per second).\n",
        "\n",
        "The Training Data Comprises :\n",
        "\n",
        "Speech Recordings\n",
        "Frame Level Phoneme State labels\n",
        "The test data comprises\n",
        "\n",
        "Speech Recordings\n",
        "Phoneme state labels are not given\n",
        "Expected from Us\n",
        "Your job is to identify the phoneme state label for each frame in the test data set. It is important to note that utterances are of variable length. We are providing you code to load and parse the raw files into the expected format. For now we are only providing dev data files as the training file is very large.\n",
        "\n",
        "Dataset\n",
        "Feature File\n",
        "[train|dev|test].npy contain a numpy object array of shape [utterances]. Each utterance is a float32 ndarray of shape [time, frequency], where time is the length of the utterance. Frequency dimension is always 40 but time dimension is of variable length.\n",
        "\n",
        "Label Files\n",
        "[train|dev]_labels.npy contain a numpy object array of shape [utterances]. Each element in the array is an int32 array of shape [time] and provides the phoneme state label for each frame. There are 138 distinct labels [0-137], one for each subphoneme.\n",
        "\n",
        "You can downlaoad the dataset from here\n",
        "\n",
        "Implementation\n",
        "The dataset files are of nearly 8GB size, We can't load them directly to google colab notebook, instead we make use of Google Drive.\n",
        "\n",
        "Upload the files on Google Drive and make use of Drive feature of the google colaboratry, type the below code, It'll show you a link, Visit that link, give confirmation, copy the auth code and paste it in the dialog box that appears. It will let you access the files in your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_l3PgUp_1aKf",
        "outputId": "6610dd6a-f2d7-450c-9f24-927c23a84280"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "-dORACFd26KL"
      },
      "source": [
        "## Loading all the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "jtQ-chOu59uw"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ptEFVD112alR"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "K5OcUhoz6Cml"
      },
      "source": [
        "Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "h-mNdysx8nMf"
      },
      "source": [
        "* **train.npy - training features**\n",
        "* [train|dev|test].npy contain a numpy object array of shape [utterances]. Each utterance is a float32 ndarray of shape [time, frequency], where time is the length of the utterance. Frequency dimension is always 13 but time dimension is of variable length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "-zvCC0mF5Aim"
      },
      "source": [
        "# loading the data file\n",
        "train_labels = np.load('/content/drive/My Drive/train_labels.npy',allow_pickle=True)  # Allow loading pickled object arrays stored in npy files.\n",
        "dev_train = np.load('/content/drive/My Drive/dev.npy',allow_pickle=True)              # Reasons for disallowing pickles include security\n",
        "dev_labels = np.load('/content/drive/My Drive/dev_labels.npy',allow_pickle=True)      # As loading pickled data can execute arbitrary code. \n",
        "test =  np.load('/content/drive/My Drive/test.npy',allow_pickle=True)                 # If pickles are disallowed, loading object arrays will fail."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "uWCgFRuZ1Q9K"
      },
      "source": [
        "x = np.concatenate(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "ihcg1MPy9ANT"
      },
      "source": [
        "* **training labels dev.npy - development/validation features**\n",
        "* [train|dev]_labels.npy contain a numpy object array of shape [utterances]. Each element in the array is an int32 array of shape [time] and provides the phoneme state label for each frame. There are 346 distinct labels [0-345], one for each subphoneme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "mFZ-rJrU1Q9N"
      },
      "source": [
        "y = np.concatenate(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "A1KbNRoUAMRi"
      },
      "source": [
        "* **dev.npy - development/validation features**\n",
        "* **dev_labels.npy - development/validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "UhTeavOZBrmx"
      },
      "source": [
        "**sample.csv - sample submission in correct format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "tLYqWxwsAoek"
      },
      "source": [
        "import pandas as pd\n",
        "sample = pd.read_csv('sample/sample.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "O7S9fwIp1Q9W"
      },
      "source": [
        "y_test = sample['label'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "B60bhdSjBfev"
      },
      "source": [
        "## Setting up the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "NNuWOZ5K1Q9X",
        "outputId": "2a9fcf67-4ccf-4b5a-9e7e-eb411df2f675"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "KQun7LDcBP_e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "uIGtqEHd1Q9a"
      },
      "source": [
        "k = 20 # context size for utterance of size (A,13) a k of 5 makes the utterance (A + 2*5, 13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "fS5nKm0jEf2S"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self,in_features=13*(1 + 2*k),h1=2048,h2=2048,h3=1024*2,h4=1024,h5=900,h6=900,h7=800,\n",
        "                 h8=800,h9 = 800,h10=800,h11=800,h12=800,h13=800,h14=800,h15=800,out_features=346):\n",
        "        \n",
        "        # How many layers?\n",
        "        # Input layer (# of features) --> hidden layer 1 (number of neurons N) --> h2 (N) --> output (346 of classes)\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features,h1)\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=h1,momentum=0.01)\n",
        "        self.fc2 = nn.Linear(h1,h2)\n",
        "        self.d2 =  nn.Dropout(0.25)\n",
        "        self.bn2 = nn.BatchNorm1d(num_features=h2,momentum=0.01)\n",
        "        self.fc3 = nn.Linear(h2,h3)\n",
        "        self.bn3 = nn.BatchNorm1d(num_features=h3,momentum=0.01)\n",
        "        self.d3 = nn.Dropout(0.4)\n",
        "        self.fc4 = nn.Linear(h3,h4)\n",
        "        self.bn4 = nn.BatchNorm1d(num_features=h4,momentum=0.01)\n",
        "        self.d4 = nn.Dropout(0.3)\n",
        "        self.fc5 = nn.Linear(h4,h5)\n",
        "        self.bn5 = nn.BatchNorm1d(num_features=h5,momentum=0.01)\n",
        "        self.d5 = nn.Dropout(0.25)\n",
        "        self.fc6 = nn.Linear(h5,h6)\n",
        "        self.bn6 = nn.BatchNorm1d(num_features=h6,momentum=0.01)\n",
        "        self.d6 = nn.Dropout(0.35)\n",
        "        \n",
        "        self.fc7 = nn.Linear(h6,h7)\n",
        "        self.bn7 = nn.BatchNorm1d(num_features=h7,momentum=0.01)\n",
        "        self.d7 = nn.Dropout(0.4)\n",
        "        \n",
        "        self.fc8 = nn.Linear(h7,h8)\n",
        "        self.bn8 = nn.BatchNorm1d(num_features=h8,momentum=0.01)\n",
        "        self.d8 = nn.Dropout(0.35)\n",
        "        \n",
        "        self.fc9 = nn.Linear(h8,h9)\n",
        "        self.bn9 = nn.BatchNorm1d(num_features=h9,momentum=0.01)\n",
        "        self.d9 = nn.Dropout(0.2)\n",
        "        \n",
        "        self.fc10 = nn.Linear(h9,h10)\n",
        "        self.bn10 = nn.BatchNorm1d(num_features=h10,momentum=0.01)\n",
        "        self.d10 = nn.Dropout(0.25)\n",
        "        \n",
        "        self.fc11 = nn.Linear(h10,h11)\n",
        "        self.bn11 = nn.BatchNorm1d(num_features=h11,momentum=0.01)\n",
        "        self.d11 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc12 = nn.Linear(h11,h12)\n",
        "        self.bn12 = nn.BatchNorm1d(num_features=h12,momentum=0.01)\n",
        "        self.d12 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc13 = nn.Linear(h12,h13)\n",
        "        self.bn13 = nn.BatchNorm1d(num_features=h13,momentum=0.01)\n",
        "        self.d13 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc14 = nn.Linear(h13,h14)\n",
        "        self.bn14 = nn.BatchNorm1d(num_features=h14,momentum=0.01)\n",
        "        self.d14 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc15 = nn.Linear(h14,h15)\n",
        "        self.bn15 = nn.BatchNorm1d(num_features=h15,momentum=0.01)\n",
        "        self.d15 = nn.Dropout(0.2)\n",
        "\n",
        "        self.out = nn.Linear(h15,out_features)\n",
        "  \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.d2(self.fc2(x))))\n",
        "        x = F.relu(self.bn3(self.d3(self.fc3(x))))\n",
        "        x = F.relu(self.bn4(self.d4(self.fc4(x))))\n",
        "        x = F.relu(self.bn5(self.d5(self.fc5(x))))\n",
        "        x = F.relu(self.bn6(self.d6(self.fc6(x))))\n",
        "        x = F.relu(self.bn7(self.d7(self.fc7(x))))\n",
        "        x = F.relu(self.bn8(self.d8(self.fc8(x))))\n",
        "        x = F.relu(self.bn9(self.d9(self.fc9(x))))\n",
        "        x = F.relu(self.bn10(self.d10(self.fc10(x))))\n",
        "        x = F.relu(self.bn11(self.d11(self.fc11(x))))\n",
        "        x = F.relu(self.bn12(self.d12(self.fc12(x))))\n",
        "        x = F.relu(self.bn13(self.d13(self.fc13(x))))\n",
        "        x = F.relu(self.bn14(self.d14(self.fc14(x))))\n",
        "        x = F.relu(self.bn15(self.d15(self.fc15(x))))\n",
        "\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "2s3tq8KtKnMI"
      },
      "source": [
        "seq_model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "eF1hOa5W1Q9d"
      },
      "source": [
        "## Working with Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "powXNf9o1Q9d",
        "outputId": "6aad4109-2ce1-444b-feac-7959a55e2f24"
      },
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.6.0+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "fvK1DBCT1Q9e"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "BMLW3F6m1Q9f"
      },
      "source": [
        "class My_Dataset(Dataset):\n",
        "    \n",
        "    def __init__(self,X,Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        if index > len(self.X) - (k + 1):\n",
        "            X = torch.Tensor(np.pad(self.X[index-k-1:].float(),pad_width=((0,(k  - len(self.X[index:].float()))),(0,0)),mode='reflect').flatten())\n",
        "        elif index <  k + 1:\n",
        "            X = torch.Tensor(np.pad(self.X[:index+k+1].float(),pad_width=((k  - index,0),(0,0)),mode='reflect').flatten())\n",
        "        else:\n",
        "            X = self.X[index-k:index+k+1].float().flatten()\n",
        "            \n",
        "        Y = self.Y[index].long()\n",
        "        return X,Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "JUp8QxlM1Q9g"
      },
      "source": [
        "X_test = torch.Tensor(np.concatenate(test))\n",
        "y_test = torch.Tensor(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "UpR0syMw1Q9h"
      },
      "source": [
        "y_val = torch.Tensor(np.concatenate(dev_labels))\n",
        "x_val = torch.Tensor(np.concatenate(dev_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "xV6ggySy1Q9i"
      },
      "source": [
        "x = torch.Tensor(x)\n",
        "y = torch.Tensor(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "r4sVPXdU1Q9j"
      },
      "source": [
        "val_dataset = My_Dataset(x_val,y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "kg3f3TS61Q9k"
      },
      "source": [
        "val_loader_args = dict(shuffle=False,batch_size=1024,num_workers=6,pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, **val_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "1dN9pGe81Q9k"
      },
      "source": [
        "test_dataset = My_Dataset(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "dnEbJtlh1Q9m"
      },
      "source": [
        "test_loader_args = dict(shuffle=False,batch_size=1024,num_workers=6,pin_memory=True) \n",
        "test_loader = DataLoader(test_dataset, **test_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "EURRfGAn1Q9m"
      },
      "source": [
        "train_dataset = My_Dataset(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ETerP8Gd1Q9n"
      },
      "source": [
        "train_loader_args = dict(shuffle=True,batch_size=1024,num_workers=6,pin_memory=True,drop_last=True) \n",
        "train_loader = DataLoader(train_dataset, **train_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "q_Ne45DqPi60"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "CLlp4GVp1Q9p",
        "outputId": "206499f7-60af-40bf-a904-8dc36f63e0e4"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "seq_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=585, out_features=4096, bias=True)\n",
              "  (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (d2): Dropout(p=0.25, inplace=False)\n",
              "  (bn2): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d3): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "  (bn4): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d4): Dropout(p=0.3, inplace=False)\n",
              "  (fc5): Linear(in_features=2048, out_features=2700, bias=True)\n",
              "  (bn5): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d5): Dropout(p=0.25, inplace=False)\n",
              "  (fc6): Linear(in_features=2700, out_features=2700, bias=True)\n",
              "  (bn6): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d6): Dropout(p=0.35, inplace=False)\n",
              "  (fc7): Linear(in_features=2700, out_features=2400, bias=True)\n",
              "  (bn7): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d7): Dropout(p=0.4, inplace=False)\n",
              "  (fc8): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn8): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d8): Dropout(p=0.35, inplace=False)\n",
              "  (fc9): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn9): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d9): Dropout(p=0.2, inplace=False)\n",
              "  (fc10): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn10): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d10): Dropout(p=0.25, inplace=False)\n",
              "  (fc11): Linear(in_features=2400, out_features=1600, bias=True)\n",
              "  (bn11): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d11): Dropout(p=0.2, inplace=False)\n",
              "  (fc12): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn12): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d12): Dropout(p=0.2, inplace=False)\n",
              "  (fc13): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn13): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d13): Dropout(p=0.2, inplace=False)\n",
              "  (fc14): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn14): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d14): Dropout(p=0.2, inplace=False)\n",
              "  (fc15): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn15): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d15): Dropout(p=0.2, inplace=False)\n",
              "  (out): Linear(in_features=1600, out_features=346, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "MMlcYxv-1Q9q",
        "outputId": "37e24626-01d8-4c2b-ec3e-f01ae0217b3c"
      },
      "source": [
        "seq_model.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=585, out_features=4096, bias=True)\n",
              "  (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (d2): Dropout(p=0.25, inplace=False)\n",
              "  (bn2): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d3): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "  (bn4): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d4): Dropout(p=0.3, inplace=False)\n",
              "  (fc5): Linear(in_features=2048, out_features=2700, bias=True)\n",
              "  (bn5): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d5): Dropout(p=0.25, inplace=False)\n",
              "  (fc6): Linear(in_features=2700, out_features=2700, bias=True)\n",
              "  (bn6): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d6): Dropout(p=0.35, inplace=False)\n",
              "  (fc7): Linear(in_features=2700, out_features=2400, bias=True)\n",
              "  (bn7): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d7): Dropout(p=0.4, inplace=False)\n",
              "  (fc8): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn8): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d8): Dropout(p=0.35, inplace=False)\n",
              "  (fc9): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn9): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d9): Dropout(p=0.2, inplace=False)\n",
              "  (fc10): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn10): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d10): Dropout(p=0.25, inplace=False)\n",
              "  (fc11): Linear(in_features=2400, out_features=1600, bias=True)\n",
              "  (bn11): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d11): Dropout(p=0.2, inplace=False)\n",
              "  (fc12): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn12): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d12): Dropout(p=0.2, inplace=False)\n",
              "  (fc13): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn13): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d13): Dropout(p=0.2, inplace=False)\n",
              "  (fc14): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn14): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d14): Dropout(p=0.2, inplace=False)\n",
              "  (fc15): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn15): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d15): Dropout(p=0.2, inplace=False)\n",
              "  (out): Linear(in_features=1600, out_features=346, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "A2n2h-ch1Q9r"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(seq_model.parameters(),lr=1e-4)\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "uuEzCbW31Q9t",
        "outputId": "7a598f14-b199-44ac-f2ae-43a193134234"
      },
      "source": [
        "seq_model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Model(\n",
              "  (fc1): Linear(in_features=585, out_features=4096, bias=True)\n",
              "  (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (d2): Dropout(p=0.25, inplace=False)\n",
              "  (bn2): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d3): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "  (bn4): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d4): Dropout(p=0.3, inplace=False)\n",
              "  (fc5): Linear(in_features=2048, out_features=2700, bias=True)\n",
              "  (bn5): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d5): Dropout(p=0.25, inplace=False)\n",
              "  (fc6): Linear(in_features=2700, out_features=2700, bias=True)\n",
              "  (bn6): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d6): Dropout(p=0.35, inplace=False)\n",
              "  (fc7): Linear(in_features=2700, out_features=2400, bias=True)\n",
              "  (bn7): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d7): Dropout(p=0.4, inplace=False)\n",
              "  (fc8): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn8): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d8): Dropout(p=0.35, inplace=False)\n",
              "  (fc9): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn9): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d9): Dropout(p=0.2, inplace=False)\n",
              "  (fc10): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn10): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d10): Dropout(p=0.25, inplace=False)\n",
              "  (fc11): Linear(in_features=2400, out_features=1600, bias=True)\n",
              "  (bn11): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d11): Dropout(p=0.2, inplace=False)\n",
              "  (fc12): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn12): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d12): Dropout(p=0.2, inplace=False)\n",
              "  (fc13): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn13): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d13): Dropout(p=0.2, inplace=False)\n",
              "  (fc14): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn14): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d14): Dropout(p=0.2, inplace=False)\n",
              "  (fc15): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn15): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d15): Dropout(p=0.2, inplace=False)\n",
              "  (out): Linear(in_features=1600, out_features=346, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "DbkAjbfe2iqv"
      },
      "source": [
        "def validation_error(model,criterion,val_loader):\n",
        "    model.eval()\n",
        "    loss = []\n",
        "    for (xii,yii) in val_loader:\n",
        "        output = model.forward(xii)\n",
        "        loss = criterion(output,yii.cuda())\n",
        "    #val_error = np.mean(np.array(loss))\n",
        "    val_error = loss\n",
        "    return val_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "kQPPhpkUgnYZ"
      },
      "source": [
        "def Testing_Model(seq_model,test_loader,epoch):\n",
        "  import numpy as np \n",
        "  import torch \n",
        "  import pandas as pd\n",
        "  torch.save(seq_model.state_dict(), f'MyModel_{epoch}.pt')\n",
        "  model2 = Model()\n",
        "  model2.load_state_dict(torch.load(f'MyModel_{epoch}.pt'));\n",
        "  device = torch.device(\"cuda\")\n",
        "  model2.to(device)\n",
        "  model2.eval()\n",
        "  test_preds = []\n",
        "  for (xj,yj) in test_loader:\n",
        "      output = model2.forward(xj)\n",
        "      test_preds.append(np.argmax(output.cpu().detach().numpy(),axis=1))\n",
        "  combined_batches = np.array(test_preds)\n",
        "  Predictions = np.concatenate(combined_batches)\n",
        "  id = [i for i in range(len(Predictions))]\n",
        "  df_pred = pd.DataFrame(data={'id':id,'label':Predictions})\n",
        "  df_pred.to_csv(f'Predictions.csv',index=False)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "_SFNHq7C1Q9x"
      },
      "source": [
        "%%time\n",
        "# EPOCHS \n",
        "seq_model.train()\n",
        "epochs = 25\n",
        "losses = []\n",
        "loss = []\n",
        "val_error = []\n",
        "validation_losses = []\n",
        "for i in range(epochs):\n",
        "    losses.append(loss)\n",
        "    validation_losses.append(val_error)\n",
        "    seq_model.train()\n",
        "    print(f'Epoch {i}, loss {loss}, validation loss: {val_error}')\n",
        "    for (xi,yi) in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        xi = xi.to(device)\n",
        "        yi = yi.to(device)\n",
        "        output = seq_model(xi)\n",
        "        loss = criterion(output,yi)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (i+1) % 5 == 0:\n",
        "      Testing_Model(seq_model,test_loader,i)\n",
        "    val_error = validation_error(seq_model,criterion,val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "KYTCzwMIbsmn"
      },
      "source": [
        "torch.save(seq_model.state_dict(), 'MyModel_V6.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "tgJrRwbq1Q9y"
      },
      "source": [
        "# Predicting on the Test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "B7B8uBXT1Q9y",
        "outputId": "9bca5c09-577a-43e3-8779-9284ad015b7a"
      },
      "source": [
        "import numpy as np \n",
        "import torch \n",
        "import pandas as pd\n",
        "model2 = Model()\n",
        "model2.load_state_dict(torch.load(f'MyModel_V11.pt'));\n",
        "model2.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=1001, out_features=4096, bias=True)\n",
              "  (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (d2): Dropout(p=0.25, inplace=False)\n",
              "  (bn2): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d3): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "  (bn4): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d4): Dropout(p=0.3, inplace=False)\n",
              "  (fc5): Linear(in_features=2048, out_features=2700, bias=True)\n",
              "  (bn5): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d5): Dropout(p=0.25, inplace=False)\n",
              "  (fc6): Linear(in_features=2700, out_features=2700, bias=True)\n",
              "  (bn6): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d6): Dropout(p=0.35, inplace=False)\n",
              "  (fc7): Linear(in_features=2700, out_features=2400, bias=True)\n",
              "  (bn7): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d7): Dropout(p=0.4, inplace=False)\n",
              "  (fc8): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn8): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d8): Dropout(p=0.35, inplace=False)\n",
              "  (fc9): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn9): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d9): Dropout(p=0.2, inplace=False)\n",
              "  (fc10): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn10): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d10): Dropout(p=0.25, inplace=False)\n",
              "  (fc11): Linear(in_features=2400, out_features=1600, bias=True)\n",
              "  (bn11): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d11): Dropout(p=0.2, inplace=False)\n",
              "  (fc12): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn12): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d12): Dropout(p=0.2, inplace=False)\n",
              "  (fc13): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn13): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d13): Dropout(p=0.2, inplace=False)\n",
              "  (fc14): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn14): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d14): Dropout(p=0.2, inplace=False)\n",
              "  (fc15): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn15): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d15): Dropout(p=0.2, inplace=False)\n",
              "  (out): Linear(in_features=1600, out_features=346, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "Qu49BECJ1Q9z",
        "outputId": "744a2cfc-d6d7-4813-ca01-fb3ac72df484"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model2.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=1001, out_features=4096, bias=True)\n",
              "  (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (d2): Dropout(p=0.25, inplace=False)\n",
              "  (bn2): BatchNorm1d(4096, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d3): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "  (bn4): BatchNorm1d(2048, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d4): Dropout(p=0.3, inplace=False)\n",
              "  (fc5): Linear(in_features=2048, out_features=2700, bias=True)\n",
              "  (bn5): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d5): Dropout(p=0.25, inplace=False)\n",
              "  (fc6): Linear(in_features=2700, out_features=2700, bias=True)\n",
              "  (bn6): BatchNorm1d(2700, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d6): Dropout(p=0.35, inplace=False)\n",
              "  (fc7): Linear(in_features=2700, out_features=2400, bias=True)\n",
              "  (bn7): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d7): Dropout(p=0.4, inplace=False)\n",
              "  (fc8): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn8): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d8): Dropout(p=0.35, inplace=False)\n",
              "  (fc9): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn9): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d9): Dropout(p=0.2, inplace=False)\n",
              "  (fc10): Linear(in_features=2400, out_features=2400, bias=True)\n",
              "  (bn10): BatchNorm1d(2400, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d10): Dropout(p=0.25, inplace=False)\n",
              "  (fc11): Linear(in_features=2400, out_features=1600, bias=True)\n",
              "  (bn11): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d11): Dropout(p=0.2, inplace=False)\n",
              "  (fc12): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn12): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d12): Dropout(p=0.2, inplace=False)\n",
              "  (fc13): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn13): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d13): Dropout(p=0.2, inplace=False)\n",
              "  (fc14): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn14): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d14): Dropout(p=0.2, inplace=False)\n",
              "  (fc15): Linear(in_features=1600, out_features=1600, bias=True)\n",
              "  (bn15): BatchNorm1d(1600, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
              "  (d15): Dropout(p=0.2, inplace=False)\n",
              "  (out): Linear(in_features=1600, out_features=346, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "35CAXj5F1Q91",
        "outputId": "0db7a52b-7fd3-429b-c919-3a4ec4f55245"
      },
      "source": [
        "model2.eval()\n",
        "test_preds = []\n",
        "print('Hello')\n",
        "for (xj,yj) in test_loader:\n",
        "    output = model2.forward(xj)\n",
        "    test_preds.append(np.argmax(output.cpu().detach().numpy(),axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mfqWQGSw1Q92",
        "outputId": "84f1ba96-63a1-4261-f3f8-2066db272552"
      },
      "source": [
        "np.concatenate(np.array(test_preds)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1593223,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qGHIkb7E1Q93",
        "outputId": "4e165a8e-94ab-490f-c5d4-c281b146125c"
      },
      "source": [
        "combined_batches = np.array(test_preds)\n",
        "combined_batches.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1556,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "liTf-D7a1Q93",
        "outputId": "376cac94-c12c-4496-ba4d-3004fe8f3fc9"
      },
      "source": [
        "Predictions = np.concatenate(combined_batches)\n",
        "Predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1593223,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "yUhHH-Am1Q94"
      },
      "source": [
        "id = [i for i in range(len(Predictions))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Z4yNt0oG1Q95",
        "outputId": "d7e8b135-de82-486c-fd82-1db387e2b724"
      },
      "source": [
        "df_pred = pd.DataFrame(data={'id':id,'label':Predictions})\n",
        "df_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1593218</th>\n",
              "      <td>1593218</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1593219</th>\n",
              "      <td>1593219</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1593220</th>\n",
              "      <td>1593220</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1593221</th>\n",
              "      <td>1593221</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1593222</th>\n",
              "      <td>1593222</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1593223 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  label\n",
              "0              0      1\n",
              "1              1      1\n",
              "2              2      1\n",
              "3              3      1\n",
              "4              4      1\n",
              "...          ...    ...\n",
              "1593218  1593218      1\n",
              "1593219  1593219      1\n",
              "1593220  1593220      1\n",
              "1593221  1593221      1\n",
              "1593222  1593222      1\n",
              "\n",
              "[1593223 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "cYDnRoc41Q96"
      },
      "source": [
        "df_pred.to_csv(f'Predictions.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "rhRAaPYM1Q97"
      },
      "source": [
        "# Evaluating Training losses "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "fq2kqF8G1Q97"
      },
      "source": [
        "losses = losses[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "7fMqgIzc1Q98",
        "outputId": "795a726a-bea2-4986-ea6c-e6d0091df88f"
      },
      "source": [
        "import seaborn as sns\n",
        "#sns.set_style('DarkGrid')\n",
        "plt.plot(losses,'--')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('CrossEntropyLoss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CrossEntropyLoss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}