{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis\n",
        "\n",
        "We will build a machine learning model that predicts the sentiment of a movie review. Sentiment analysis is an NLP technique used to determine whether data is positive, negative, or neutral. It’s really helpful for businesses because it helps understand the overall opinions of their customers."
      ],
      "metadata": {
        "id": "foSvSM1_9ETn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project, we will use an IMDB dataset that contains 50k movie reviews. with 2 columns (review and sentiment). The goal is to build the best machine learning model that predicts the sentiment given a movie review. We only have to predict whether a movie review is positive or negative. This is known as binary text classification because there are only two possible outcome"
      ],
      "metadata": {
        "id": "tDTwU4ld9NL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the data set from [Kaggle](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/) and upload it to your notebook"
      ],
      "metadata": {
        "id": "VlF6Ouva9aDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stuff for plotting and visualization"
      ],
      "metadata": {
        "id": "LXflJzIwLmlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
        "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=13)    # legend fontsize\n",
        "plt.rc('font', size=13)          # controls default text sizes"
      ],
      "metadata": {
        "id": "0e3DYmF-Lpri"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the Data"
      ],
      "metadata": {
        "id": "kLRSdFE2941t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading the Dataset\n",
        "\n",
        "We’ll read the file using the Pandas library."
      ],
      "metadata": {
        "id": "hfcdMWE798l0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uxaWPrN485Us",
        "outputId": "736b6c11-9d9b-40cb-81fa-201b05a9610d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-69059be5-349c-488f-bf61-f794e6b638f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69059be5-349c-488f-bf61-f794e6b638f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69059be5-349c-488f-bf61-f794e6b638f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69059be5-349c-488f-bf61-f794e6b638f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_review = pd.read_csv('IMDB.csv', engine ='python')\n",
        "df_review"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_review.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRNrv58XDiYU",
        "outputId": "b5e3360a-f7af-4cf7-ff06-5e989d7e69f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['review', 'sentiment'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains 50000 rows; however, to train our model faster in the following steps, we’re going to take a smaller sample of 10000 rows. This small sample will contain 9000 positive and 1000 negative reviews to make the data imbalanced"
      ],
      "metadata": {
        "id": "hb2fuUufH2wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_positive = df_review[df_review['sentiment']=='positive'][:9000]\n",
        "\n",
        "df_negative = df_review[df_review['sentiment']=='negative'][:1000]\n",
        "\n",
        "df_review_imb = pd.concat([df_positive, df_negative])"
      ],
      "metadata": {
        "id": "6D4Ld2SY-aC5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette('deep')\n",
        "\n",
        "plt.figure(figsize=(8,4), tight_layout=True)\n",
        "plt.bar(x=['Positive', 'Negative'],\n",
        "        height=df_review_imb.value_counts(['sentiment']),\n",
        "        color=colors[:2])\n",
        "plt.title('Sentiment')\n",
        "plt.savefig('sentiment.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "URMs-bWDLv-k",
        "outputId": "eff790b8-d887-4e01-811f-4f5d21273334"
      },
      "execution_count": 29,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review_imb.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_2oOuu5JnC2",
        "outputId": "f5862750-2a4b-44bd-f7ee-343dcd9d2fee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dealing with Imbalanced Classes\n",
        "\n",
        "\n",
        "To resample our data we use the imblearn library. We can either undersample positive reviews or oversample negative reviews"
      ],
      "metadata": {
        "id": "UnM8uWuIICrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler     # import a random under sampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "\n",
        "df_review_bal, df_review_bal['sentiment'] = rus.fit_resample(df_review_imb[['review']], df_review_imb['sentiment'])     # undersample \n",
        "\n",
        "\n",
        "df_review_bal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1075
        },
        "id": "mlbQAMMPCtgz",
        "outputId": "0f0474be-2756-45ae-8ad5-62fb153dfbd4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-80cd4fe4-61fa-4718-9d3e-f5ecee00f30f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I saw this movie when I was about 12 when it c...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Knute Rockne led an extraordinary life and his...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>At the height of the 'Celebrity Big Brother' r...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>This is another of Robert Altman's underrated ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>This movie won a special award at Cannes for i...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>You'd be forgiven to think a Finnish director ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80cd4fe4-61fa-4718-9d3e-f5ecee00f30f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80cd4fe4-61fa-4718-9d3e-f5ecee00f30f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80cd4fe4-61fa-4718-9d3e-f5ecee00f30f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 review sentiment\n",
              "0     Basically there's a family where a little boy ...  negative\n",
              "1     This show was an amazing, fresh & innovative i...  negative\n",
              "2     Encouraged by the positive comments about this...  negative\n",
              "3     Phil the Alien is one of those quirky films wh...  negative\n",
              "4     I saw this movie when I was about 12 when it c...  negative\n",
              "...                                                 ...       ...\n",
              "1995  Knute Rockne led an extraordinary life and his...  positive\n",
              "1996  At the height of the 'Celebrity Big Brother' r...  positive\n",
              "1997  This is another of Robert Altman's underrated ...  positive\n",
              "1998  This movie won a special award at Cannes for i...  positive\n",
              "1999  You'd be forgiven to think a Finnish director ...  positive\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review_bal.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b235Nl3NJfGh",
        "outputId": "314ab04d-fc1a-4a18-983b-0dbcb9cc269b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we create a new instance of ```RandomUnderSampler``` (rus), we add ```random_state=0``` just to control the randomization of the algorithm. Then we resample the imbalanced dataset ```df_review_imb```  by fitting rus with ```rus.fit_resample(x, y)``` where “x” contains the data which have to be sampled and “y” corresponds to labels for each sample in “x”.\n",
        "After this, x and y are balanced and we’ll store it in a new dataset named ```df_review_bal```.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QcjEufRYI-3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## compare the data\n",
        "\n",
        "print(df_review_imb.value_counts('sentiment'))\n",
        "print(df_review_bal.value_counts('sentiment'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNlFAE1NInGz",
        "outputId": "484c104f-49ba-4007-a748-494495a1163a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "positive    9000\n",
            "negative    1000\n",
            "dtype: int64\n",
            "sentiment\n",
            "positive    1000\n",
            "negative    1000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you get an error while using the ```Random Under sampler```, \n",
        "try the code below\n",
        "\n",
        "\n",
        "```\n",
        "length_negative = len(df_review_imb[df_review_imb['sentiment']=='negative'])\n",
        "df_review_positive = df_review_imb[df_review_imb['sentiment']=='positive'].sample(n=length_negative)\n",
        "df_review_non_positive = df_review_imb[~(df_review_imb['sentiment']=='positive')]\n",
        "\n",
        "df_review_bal = pd.concat([df_review_positive, df_review_non_positive])\n",
        "df_review_bal.reset_index(drop=True, inplace=True)\n",
        "df_review_bal['sentiment'].value_counts()\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ukQyRn5uJyB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into train and test set\n",
        "\n",
        "The ```train```  dataset will be used to fit the model , while the ```test``` dataset will be used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
        "\n",
        "We will use sklearn's ```train_test_split``` to do the job.\n",
        "\n"
      ],
      "metadata": {
        "id": "VE5cC4afKL_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df_review_bal, test_size= 0.33, random_state = 135)"
      ],
      "metadata": {
        "id": "OJB56GsPJWDQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **train_x**: Independent variables (review) that will be used to train the model. Since we specified test_size $= 0.33, 67\\%$ of observations from the data will be used to fit the model.\n",
        "*  **train_y**: Dependent variables (sentiment) or target label that need to be predicted by this model.\n",
        " \n",
        "\n",
        "* **test_x**: The remaining 33% of independent variables that will be used to make predictions to test the accuracy of the model.\n",
        "*  **test_y**: Category labels that will be used to test the accuracy between actual and predicted categories.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r94mcoUAMBZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the dependent and the independent variables within our train and test set\n",
        "\n",
        "train_x ,train_y = train['review'], train['sentiment']\n",
        "\n",
        "test_x, test_y = test['review'], test['sentiment']"
      ],
      "metadata": {
        "id": "Lk1Hh2aHK81z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtwHR85yLOD4",
        "outputId": "3378fe8e-88d4-4fe5-c84b-b36211f0690c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    670\n",
              "positive    670\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Representation ( Bag Of Words)\n",
        "\n",
        "The classifiers and learning algorithms expect numerical feature vectors rather than raw text documents. We need to convert the text to a more manageable representation. There are many text representation techniques such as one-hot encoding, bag of words, and wor2vec.\n",
        "For this, we’ll use bag of words (BOW) since we care about the frequency of the words in text reviews; however, the order of words is irrelevant. Two common ways to represent bag of words are CountVectorizer and Term Frequency, Inverse Document Frequency (TF-IDF)\n"
      ],
      "metadata": {
        "id": "qkvMywpOMkdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Count Vectorizer\n",
        "\n",
        "The CountVectorizer gives us the frequency of occurrence of words in a document. "
      ],
      "metadata": {
        "id": "Bp11XZoCMrqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Term Frequency, Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "The TF-IDF computes “weights” that represents how important a word is to a document in a collection of documents (aka corpus). The TF-IDF value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word."
      ],
      "metadata": {
        "id": "peMSPeXyNAY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turning our text data into numerical vectors\n",
        "\n",
        "We want to identify unique words for the positive and negative reviews, we will chose the TF-IDF model."
      ],
      "metadata": {
        "id": "fny61zddNMey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we create a new instance of TfidfVectorizer(tfidf), we removed English stopwords and then fit (finds the internal parameters of a model) and transform (applies the parameters to the data) the train_x (text reviews)"
      ],
      "metadata": {
        "id": "ChIUTA4JOcRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "train_x_vector = tfidf.fit_transform(train_x)\n",
        "train_x_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4tmdKW4MijL",
        "outputId": "b6613b9d-f8e2-4efb-8045-d56f4294069f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1340x20312 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 117669 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to dispay this matrix,use the code below. But there will be a lot of $0$ values, since its a sparse matrix where the matrix is a $1340 \\times 20312$ in dimension ,and only $117669$ elements are different from $0$."
      ],
      "metadata": {
        "id": "OpnrZat3Ok8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.sparse.from_spmatrix(train_x_vector,\n",
        "                                  index=train_x.index,\n",
        "                                  columns=tfidf.get_feature_names())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2341
        },
        "id": "7bUsmJ2lOZe4",
        "outputId": "a98ab752-60bc-483c-aaac-de1c38ea291d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a2410efd-46b5-49b9-9015-e58748272e1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>01pm</th>\n",
              "      <th>02</th>\n",
              "      <th>04</th>\n",
              "      <th>06</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>100m</th>\n",
              "      <th>101</th>\n",
              "      <th>104</th>\n",
              "      <th>1040</th>\n",
              "      <th>1040a</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>11th</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>127</th>\n",
              "      <th>12th</th>\n",
              "      <th>13</th>\n",
              "      <th>130</th>\n",
              "      <th>1300s</th>\n",
              "      <th>133</th>\n",
              "      <th>13th</th>\n",
              "      <th>14</th>\n",
              "      <th>1473</th>\n",
              "      <th>14th</th>\n",
              "      <th>15</th>\n",
              "      <th>150</th>\n",
              "      <th>150th</th>\n",
              "      <th>158</th>\n",
              "      <th>16</th>\n",
              "      <th>161</th>\n",
              "      <th>166</th>\n",
              "      <th>...</th>\n",
              "      <th>zentropa</th>\n",
              "      <th>zepher</th>\n",
              "      <th>zephyr</th>\n",
              "      <th>zeppelin</th>\n",
              "      <th>zero</th>\n",
              "      <th>zeros</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zhaan</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zheng</th>\n",
              "      <th>zhu</th>\n",
              "      <th>ziegler</th>\n",
              "      <th>zillionaire</th>\n",
              "      <th>ziman</th>\n",
              "      <th>zinc</th>\n",
              "      <th>zineb</th>\n",
              "      <th>zingers</th>\n",
              "      <th>ziyi</th>\n",
              "      <th>zizek</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zoey</th>\n",
              "      <th>zola</th>\n",
              "      <th>zombi</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombies</th>\n",
              "      <th>zombiez</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoned</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zooming</th>\n",
              "      <th>zooms</th>\n",
              "      <th>zoot</th>\n",
              "      <th>zues</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
              "      <th>élan</th>\n",
              "      <th>ísnt</th>\n",
              "      <th>île</th>\n",
              "      <th>ünfaithful</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112876</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.095235</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1585</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1304</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.181981</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1211</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041563</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1340 rows × 20312 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2410efd-46b5-49b9-9015-e58748272e1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2410efd-46b5-49b9-9015-e58748272e1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2410efd-46b5-49b9-9015-e58748272e1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       00  000  007   01  01pm  ...  zzzzzzzzzzzzzzzzzz  élan  ísnt  île  ünfaithful\n",
              "409   0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "778   0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "1585  0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "1521  0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "1304  0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "...   ...  ...  ...  ...   ...  ...                 ...   ...   ...  ...         ...\n",
              "1404  0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "459   0.0  0.0  0.0  0.0   0.0  ...            0.181981   0.0   0.0  0.0         0.0\n",
              "1243  0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "1211  0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "671   0.0  0.0  0.0  0.0   0.0  ...            0.000000   0.0   0.0  0.0         0.0\n",
              "\n",
              "[1340 rows x 20312 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (20312) exceeds max_columns (20) limiting to first (20) columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x_vector = tfidf.transform(test_x)"
      ],
      "metadata": {
        "id": "d2K75BNuOpkh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " We could better prepare the text data in order to develop better models by using tokenization and removing extra words we consider irrelevant apart from the stopword list CountVectorizer and Tfidf have by default. "
      ],
      "metadata": {
        "id": "nrUhcLGxP59h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection\n",
        "Now, we have the data, we can experiment varioous machine learning models and evaluate their accuracy.\n"
      ],
      "metadata": {
        "id": "8mpr4ypAP78O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Support Vector Machine (SVM)\n",
        "To fit an SVM model, we need to introduce the input (text reviews as numerical vectors) and output (sentiment)\n"
      ],
      "metadata": {
        "id": "CMccHZ1XQLOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(kernel='linear')\n",
        "svc.fit(train_x_vector, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzd1gHmmP1PK",
        "outputId": "4f9638a0-0722-4a26-f286-42f9ef9522af"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After fitting svc we can predict whether a review is positive or negative with the .predict() method."
      ],
      "metadata": {
        "id": "KyNeCOzuQcOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(svc.predict(tfidf.transform(['How this film could be classified as Drama, I have no idea. If I were John Voight and Mary Steenburgen, I would be trying to erase this from my CV. It was as historically accurate as Xena and Hercules. Abraham and Moses got melded into Noah. Lot, Abrahams nephew, Lot, turns up thousands of years before he would have been born. Canaanites wandered the earth...really? What were the scriptwriters thinking? Was it just ignorance I remember something about Noah and animals, and Lot and Canaanites and all that stuff from Sunday School or were they trying to offend the maximum number of people on the planet as possible- from Christians, Jews and Muslims, to historians, archaeologists, geologists, psychologists, linguists ...as a matter of fact, did anyone not get offended? Anyone who had even a modicum of taste would have winced at this one!'])))\n",
        "print(svc.predict(tfidf.transform(['An excellent movie'])))\n",
        "print(svc.predict(tfidf.transform(['I did not like this movie at all'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKHtKVupQY8O",
        "outputId": "7395a771-b1a9-4a66-885e-bc60d29f481e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative']\n",
            "['positive']\n",
            "['negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(svc.predict(tfidf.transform(['One of the other reviewers has mentioned that after watching just 1 Oz episode youll be hooked'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA_qp21bQeau",
        "outputId": "30479adc-9d8f-40ab-fea4-305c0945eafa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(svc.predict(tfidf.transform(['I saw this movie when I was about 12 when it came out. I recall the scariest scene was the big bird eating men dangling helplessly from parachutes right out of the air. The horror. The horror.<br /><br />As a young kid going to these cheesy B films on Saturday afternoons, I still was tired of the formula for these monster type movies that usually included the hero, a beautiful woman who might be the daughter of a professor and a happy resolution when the monster died in the end. I didnt care much for the romantic angle as a 12 year old and the predictable plots. I love them now for the unintentional humor.<br /><br />But, about a year or so later, I saw Psycho when it came out and I loved that the star, Janet Leigh, was bumped off early in the film. I sat up and took notice at that point. Since screenwriters are making up the story, make it up to be as scary as possible and not from a well-worn formula. There are no rules.'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltaWN0ujRAqB",
        "outputId": "37d2ac82-2a98-43ab-f814-769002a2b96f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Tree\n",
        " To fit a decision tree model, we need to introduce the input (text reviews as numerical vectors) and output (sentiment)"
      ],
      "metadata": {
        "id": "eyIlZYY4RvRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dec_tree = DecisionTreeClassifier()\n",
        "dec_tree.fit(train_x_vector, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6ramm2mRXLM",
        "outputId": "0461b574-69e8-40a6-b6dd-95347bd5c933"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dec_tree.predict(tfidf.transform(['An excellent movie'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM1i2fE-R2kB",
        "outputId": "e134ab1d-9f89-4773-dbe5-c1b38605802a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dec_tree.predict(tfidf.transform(['One of the other reviewers has mentioned that after watching just 1 Oz episode youll be hooked'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7c8j_1zR-Xz",
        "outputId": "3057b6f5-9b89-49f9-af4e-b76008062626"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naive Bayes\n",
        "To fit a Naive Bayes model, we need to introduce the input (text reviews as numerical vectors) and output (sentiment)"
      ],
      "metadata": {
        "id": "JlekG1meSTCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(train_x_vector.toarray(), train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWfh2m0QSEJQ",
        "outputId": "ce50e01d-8be2-4db4-a414-652aad2674d5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression\n",
        "To fit a Logistic Regression model, we need to introduce the input (text reviews as numerical vectors) and output (sentiment)"
      ],
      "metadata": {
        "id": "dnLu8LSHSiTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(train_x_vector, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrI8GoWdSXSx",
        "outputId": "8c4c60cf-5cca-410c-cb3a-3fccdae20b04"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy Detection"
      ],
      "metadata": {
        "id": "nBOZBe_rSm6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc.score(test_x_vector, test_y)\n",
        "# support vector machine score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXiiZGZdSabx",
        "outputId": "58b5c0d0-51f8-4c79-a0e8-22f96be5ded7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.843939393939394"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_tree.score(test_x_vector, test_y)\n",
        "# decision tree score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khYfozojSq2_",
        "outputId": "f124bffc-b289-4270-93c9-269a0d52c261"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6727272727272727"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnb.score(test_x_vector.toarray(), test_y)\n",
        "# naive bayes score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frg_cHMJStrL",
        "outputId": "76aa14d7-cf07-47c6-8fc4-f8452883b22e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6287878787878788"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg.score(test_x_vector, test_y)\n",
        "\n",
        "# log regression score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbde3HJXSvP7",
        "outputId": "b364ba91-47a3-457e-fe76-461c228e7b9f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8348484848484848"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM and Logistic Regression perform better than the other two classifiers, with SVM having a slight advantage (84% of accuracy)."
      ],
      "metadata": {
        "id": "ab2Yo9FtTBcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1 Score\n",
        "\n",
        "F1 Score is the weighted average of Precision and Recall. Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial. Also, F1 takes into account how the data is distributed, so it’s useful when you have data with imbalance classes.\n",
        "F1 score is calculated with the following formula \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
        "F1 score reaches its best value at 1 and worst score at 0.\n",
        "```\n",
        "\n",
        "\n",
        "To obtain the F1 score, we need the true labels and predicted labels\n",
        "```f1_score(y_true, y_pred)```"
      ],
      "metadata": {
        "id": "PDHXZnGbTH57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(test_y, svc.predict(test_x_vector),\n",
        "         labels=['positive', 'negative'],\n",
        "         average=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuS9UE4gSwUZ",
        "outputId": "eb81f52c-7cfc-4189-b628-84d9a69851a1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.84919473, 0.83830455])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scores obtained for positive labels is 0.84, while negative labels is 0.83."
      ],
      "metadata": {
        "id": "4kr__6M-TclY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Report\n",
        "\n",
        "We can also build a text report showing the main classification metrics that include those calculated before. To obtain the classification report, we need the true labels and predicted labels classification_report(y_true, y_pred)"
      ],
      "metadata": {
        "id": "Wxe2Y7AGTd_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_y, \n",
        "                            svc.predict(test_x_vector),\n",
        "                            labels=['positive', 'negative']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYnwtcWlTaYk",
        "outputId": "cffd2b64-1f17-4b4e-d5ba-b7530b12ac97"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.82      0.88      0.85       330\n",
            "    negative       0.87      0.81      0.84       330\n",
            "\n",
            "    accuracy                           0.84       660\n",
            "   macro avg       0.85      0.84      0.84       660\n",
            "weighted avg       0.85      0.84      0.84       660\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix\n",
        "A confusion matrix) is a table that allows visualization of the performance of an algorithm. This table typically has two rows and two columns that report the number of false positives, false negatives, true positives, and true negatives (check the graph in this link in case you don’t understand these terms)\n",
        "To obtain the confusion matrix, we need the true labels and predicted labels."
      ],
      "metadata": {
        "id": "OSdRKQgTTm23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(test_y, \n",
        "                            svc.predict(test_x_vector), \n",
        "                            labels=['positive', 'negative'])"
      ],
      "metadata": {
        "id": "K0gSutwPTkOJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conf_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCtMPvv8Trq4",
        "outputId": "9c749945-7e9b-40be-ec66-657ebd75f2b4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[290  40]\n",
            " [ 63 267]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning the Model\n"
      ],
      "metadata": {
        "id": "Crj0vvd5Txsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grid Search CV\n",
        "\n",
        "This is technique consists of an exhaustive search on specified parameters in order to obtain the optimum values of hyperparameters. To do so, we write the following code."
      ],
      "metadata": {
        "id": "HxiZRGbET0Jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "#set the parameters\n",
        "parameters = {'C': [1,4,8,16,32] ,'kernel':['linear', 'rbf']}\n",
        "svc = SVC()\n",
        "svc_grid = GridSearchCV(svc,parameters, cv=5)\n",
        "\n",
        "svc_grid.fit(train_x_vector, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXc4txGzTusc",
        "outputId": "b0a6add3-17a7-4aea-bb6e-c7a95da85845"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=SVC(),\n",
              "             param_grid={'C': [1, 4, 8, 16, 32], 'kernel': ['linear', 'rbf']})"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see the code it’s not so different from the one we wrote to fit the SVM model; however, now we specified some parameters to obtain the optimum model.\n",
        "After fitting the model, we obtain the best score, parameters, and estimators with the following code."
      ],
      "metadata": {
        "id": "3bh_MUmCUCpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(svc_grid.best_params_)\n",
        "print(svc_grid.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guU7bOMcT5sX",
        "outputId": "ea60fdd0-90d6-4666-e722-b090a8f2914e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 4, 'kernel': 'rbf'}\n",
            "SVC(C=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JOTAX32aUFg-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}